<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Point-GCC</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
                Point-GCC: Universal Self-supervised 3D Scene Pre-training via Geometry-Color Contrast
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                <span class="author-block">
                    <a href="https://asterisci.github.io/" target="_blank">Guofan Fan</a><sup>1,2</sup>,
                </span>
                <span class="author-block">
                    <a href="https://qizekun.github.io/" target="_blank">Zekun Qi</a><sup>1,2</sup>,
                </span>
                <span class="author-block">
                    <a href="https://github.com/yibai-shi" target="_blank">Wenkai Shi</a><sup>1</sup>,
                </span>
                <span class="author-block">
                     <a href="https://group.iiis.tsinghua.edu.cn/~maks/leader.html" target="_blank">Kaisheng Ma</a><sup>3*</sup>,
                </span>
            </div>

            <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Xi'an Jiaotong University</span> 
            <span class="author-block"><sup>2</sup>IIISCT</span>
            <span class="author-block"><sup>3</sup>IIIS, Tsinghua University</span><br>
            <span class="eql-cntrb"><small><sup>*</sup>Corresponding Author.</small></span>
            </div>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                    <a href="https://arxiv.org/abs/2305.19623" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>arXiv(soon)</span>
                    </a>
                </span>
                <!-- Github link -->
                <span class="link-block">
                    <a href="#" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                    </a>
                </span>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column is-four-fifths">
                  <div class="item">
                      <!-- Your image here -->
                      <!-- <div class="images-container"> -->
                        <img src="static/images/overview.png" alt="overview" />
                        <!-- <img src="static/images/adv1.png" alt="ap-clip" /> -->
                    <!-- </div> -->
                      <h2 class="subtitle" style="font-size: 16px;">
                      </h2>
                      Point-GCC utilizes the Siamese network
                      to extract the features of geometry and color with positional embedding respectively. Then we
                      implement the hierarchical supervision on extracted features which contains point-level contrast and
                      reconstruct and object-level contrast based on the deep clustering module.
                    </h2>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End image carousel -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Geometry and color information provided by the point clouds are both crucial
            for 3D scene understanding. Two pieces of information characterize the different
            aspects of point clouds, but existing methods lack an elaborate design for the
            discrimination and relevance. Hence we explore a 3D self-supervised paradigm that
            can better utilize the relations of point cloud information. Specifically, we propose
            a universal 3D scene pre-training framework via Geometry-Color Contrast (PointGCC), which aligns geometry and color information using a Siamese network. To
            take care of actual application tasks, we design (i) hierarchical supervision with
            point-level contrast and reconstruct and object-level contrast based on the novel
            deep clustering module to close the gap between pre-training and downstream
            tasks; (ii) architecture-agnostic backbone to adapt for various downstream models.
            Benefiting from the object-level representation associated with downstream tasks,
            Point-GCC can directly evaluate model performance and the result demonstrates
            the effectiveness of our methods. Transfer learning results on a wide range of
            tasks also show consistent improvements across all datasets. e.g., new state-of-theart object detection results on SUN RGB-D and S3DIS datasets.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="hero-body">
      <div class="container  is-max-desktop">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                  <h2 class="title is-3">Overview</h2>
                  <div class="item">
                      <!-- Your image here -->
                      <img src="static/images/methods.png" alt="method" />
                      <h2 class="subtitle has-text-centered" style="font-size: 16px;">
                        (a) The deep clustering module obtains pseudo prediction for different features and enforces
                        consistent with the swapped partition distribution from the Sinkhorn-Knop algorithm. <br>
                        (b) Point-GCC
                        generates the pseudo-labels by utilizing cluster prediction from both branches and projects to groundtruth labels for unsupervised semantic segmentation using Hungarian matching alignment.
                      </h2>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>

<section class="hero is-small">
    <div class="hero-body">
        <div class="container  is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">3D Object detection results</h2>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/res1.png" alt="res1" style="width: 80%;"/>
                        <h2 class="subtitle has-text-centered" style="font-size: 16px;">
                            + means
                            fine-tuning with pre-training on the corresponding dataset. * means that we evaluate the performance
                            on VoteNet with the stronger MMDetection3D implementation for a fair comparison. † means with
                            extra training dataset ScanNetV2.
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </div>
  </section>

<section class="hero is-small">
  <div class="hero-body">
      <div class="container  is-max-desktop">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                  <h2 class="title is-3">3D semantic segmentation results by different level of supervision</h2>
                  <div class="item">
                      <!-- Your image here -->
                      <img src="static/images/res2.png" alt="res2" style="width: 80%;"/>
                      <h2 class="subtitle has-text-centered" style="font-size: 16px;">
                        + means fine-tuning with pre-training on the corresponding dataset.
                      </h2>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @article{point-gcc,
        title={{Point-GCC:} Universal Self-supervised 3D Scene Pre-training via Geometry-Color Contrast},
        author={Fan, Guofan and Qi, Zekun and Shi, Wenkai and and Ma, Kaisheng},
        journal={arXiv preprint arXiv:2305.19623},
        year={2023}
    }
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
